Name: Kumar Saurav
Roll number: 160050057
========================================


================
     TASK 2
================


1. Run your code on datasets/garden.csv, with different values of k. Looking at the performance plots, does the SSE of k-means algorithm ever increase as the iterations are made? (1 mark)
Answer: No. The k-means algorithm is designed such that it updates the points only if the SSE decreases in an iteration. The algorithm is supposed to halt when the SSE starts to increase. This point has been proved in class. In the algorithm, we first reassign points to cluster means based on the minimum distance to the point. This either reduces the contribution to SSE of each point or keeps it unchanged. In the next step, we change the means to the actual mean of the points assigned to the same cluster. This is precisely the point that minimises the SSE when we keep the cluster fixed and we are allowed to only change the cluster mean points. Therefore, in each step, we are reducing the SSE.

3. Look at the files 3lines.png and mouse.png. Manually draw cluster boundaries around the 3 clusters visible in each file (no need to submit the hand drawn clusters). Test the k-means algorithm on the datasets datasets/3lines.csv and datasets/mouse.csv. How does the algorithm’s clustering compare with the clustering you would do by hand? Why do you think this happens? (1 mark)
Answer: The clustering in 3lines.png is vastly different from that of the hand-drawn boundaries. This is because of the initialisation. If the initial cluster mean points were the centres of each of the lines, then the results of the hand-drawn and computed clusters would have been the same. However, due to the random initialisation, each of the cluster mean points have a point in atleast 2 of the lines out of the 3. Using gradient descent, we get stuck in a local minima this problem.



================
     TASK 3
================

1. For each dataset, with kmeansplusplus initialization algorithm, report “average SSE” and "average iterations". Explain the results. (2 mark)
Answer:

Dataset     |  Initialization | Average SSE  | Average Iterations
==================================================================
   100.csv  |        forgy    |             |
   100.csv  |        kmeans++ |             |
  1000.csv  |        forgy    |             |
  1000.csv  |        kmeans++ |             |
 10000.csv  |        forgy    |             |
 10000.csv  |        kmeans++ |             |


================
  TASK 4
================

1. Can you observe from the visualization that k-medians algorithm is more robust to outliers as compared to k-means? Why do you think this happens? (1.5 marks)
Answer:

================
  TASK 8
================

1. What do you observe as we reduce the number of clusters (k)? Answer in reference to the quality of decompressed image. (0.5 mark)
Answer:


2. You can observe that for the small number of clusters, the degree of compression (original size/compressed size) is about the same as that of when we use larger number of clusters even though we need to store lesser number of colors. Can you tell why? How can we increase this ratio in case of smaller number of clusters? [1 mark]
Answer: 
